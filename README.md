# [docker-tutorial](https://docs.docker.com/get-started/part2/)
Gentle introduction to docker


# Containers


## First commands
```
docker --version

docker info
docker version

docker image ls --all
docker container ls --all
docker container ls -aq

docker run hello-world
```


## Building an image
The . specifies the current directory, omitting the :vxxxxx means that the image will be versioned at "latest" instead of "xxxxx"

```
docker build --tag=myImageName .
docker build --tag=myImageName:v1.0.1 .
```


## Running an image - Deploying the image as container
run image port 4000 on local host is mapped to port 80 on container
app.py specified that the "server" would run at 0.0.0.0:80 which is mapped to our localhost:4000
```
docker run -p 4000:80 friendlyhello_mytag
```
visit
```
http://localhost:4000
```
or execute
```
curl http://localhost:4000
```
Note that port 80 is first exposed when the container is setup in the docker file (EXPOSE ).
Then a mapping can be done between the container's port 80 and localhost:4000 (docker run -p)

Also note that myImageName is the name of the image that generated the container.
Once the container is spawned it gets its own ID (similar to process id) and its own name

Log in runninng container with
```
docker exec -it <container-name> sh
docker exec -it <container-name> bash
```
Also note that the app's host name is the container id


## Pushing Image to Registry

```
A registry is a collection of repository which is a collection of images
An account can create many repositories like github
```

```
docker login
```

The notation for associating a local image with a repository on a registry is username/repository:tag. 
The tag is optional, but recommended, since it is the mechanism that registries use to give Docker images a version
docker tag myImageName kmurphs/get-started:part2

At this point we just tagged the image in a way that allows it to be pushed to the repository. However, at this point,
it is an image like any other and can be viewed with:
```
docker image ls 
```

Once the tagging is done,
```
docker push username/repository:tag
```
Now it is visible in dockerhub


The follwing will pull the specific image with the specified tag from dockerhub if the image is not found on your system
```
docker run -p 4000:80 username/repository:tag
```



# Services

The docker environment has 3 levels:
```
Stak
Services
Container
```

We dealt with containers in the first part

```
A service is a construct built on top of containers that makes it possible to scale by spawning more containers 
replica (generated by the same image) doing the same things but sharing the load and increasing the service's 
processing power (horizontal scaling)
```

### From the docs
> In a distributed application, different pieces of the app are called “services”. For example, if you imagine a video sharing site, it probably includes a service for storing application data in a database, a service for video transcoding in the background after a user uploads something, a service for the front-end, and so on.

> Services are really just “containers in production.” A service only runs one image, but it codifies the way that image runs—what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.


### docker-compose.yml

You configure and run the service by using the file ***``docker-compose.yml``***. See example below
```
version: "3"
services:
  web:
    # replace username/repo:tag with your name and image details
    image: username/repo:tag
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: "0.1"
          memory: 50M
      restart_policy:
        condition: on-failure
    ports:
      - "4000:80"
    networks:
      - webnet
networks:
  webnet:
```


0. **Create an app (stack) with services as listed, and networks as listed**
The service and network exist as addressable and identifiable entities

1. Create the services listed (In this case only one service is listed)
2. The service is **named** *web*
3. Pull the service's image from ...
4. Deployment policy:
    * 5 replicas at any given time
    * Limit cpu usage to 10% for each replica
    * Allocate 50M RAM of memory to each replica
    * On failure, restart failed replica
5. Forward replica's internal port 80 to localhost's port 4000 via a load-balancing network called **webnet** defined after

6. Since webnet does not have any specified parameters, it is configured with default parameters


## Run the Service

```
docker swarm init
```

Instruction is explained later in part 4

```
docker stack deploy -c docker-compose.yml getstartedlab
```

The name ``getstartedlab`` is the name we give to our app/**stack**

List running services
```
docker service ls
```
List services in a stack
```
docker stack services <your app/stack name e.g. getstartedlab>
```
The name of a service is ``<your app/stack name e.g. getstartedlab>_<the network it's configured to use>`` e.g getstartedlab_web
A container within a service is called task and receives the name ``<service name>.<incrementing counter>``
The container still get listed with ``docker container ls``
```
docker service ps getstartedlab_web
```

```
curl -4 http://localhost:4000
```
Will convince of the load balancing, you will hit different containers as you curl into the docker app/stack


Rerun ``docker stack deploy -c docker-compose.yml getstartedlab`` with updated ``docker-compose.yml`` to update the deployment configuration.


## Stop the Service

Stop the app/stack
```docker stack rm getstartedlab```

Leave the swarm
```docker swarm leave --force```




# Swarms

Containers were replicated and integrated by a service. But so far they have been running on the same host/machine.
Swarms allow ***Multi-container, multi-machine applications***.

Note that machine here can mean physical or virtual machines

A swarm (or swarm cluster) is therefore a "dockerized" cluster of machines (dockerized as opposed to other methods of joining machines together and still running Multi-container, multi-machine applications)

## Swarms CLusters
A group of physical and/or virtual machines that are running Docker and joined into a cluster.
One machine is selected to be the ***Swarm Manager*** who executes all the instructions we have used so far, and authorize new machines to join the cluster.
The other machines are called ***nodes/workers***. They only provide capacity and have no control/influence whatsoever over any other machines. 

```
docker swarm init
docker swarm join
```


      ***Setup Windows 10 to run virtual machines***
      Run HyperV Manager, click Virtual Switch Manager, then Create Virtual Switch of type External with Sharing of active network adapter Enabled.
      
      ```
      docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm1
      docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm2
      ```


On Windows the terminal hanged at waiting for host to start. To fix this:
This [stack overlfow answer] helped: (https://stackoverflow.com/questions/47728330/docker-machine-stuck-while-creating)
  * If you type: ``docker-machine ls``, you will see that the VM is running but hey have no URL. This says that the network address cannot be assigned
  * Use HyperV Manager to turn off the vms, and make sure they use an external switch adapter that's actually part of a **running** network (Wireless/Ethernet)
  * User HyperV Manager to start the vms, and confirm the issue is solved by issuing another ``docker-machine ls``. The machine should have an IP address now
  * **Note**: This [docker doc](https://docs.docker.com/machine/drivers/hyper-v/#example) suggest to reboot after setting up the switch adapter.

At this point, another error was generated on my windows system.
The ``docker-machine ls`` showed that even though the IP address were set properly, the following errors showed up:
  * ```
  Unable to query docker version: Get https://192.168.8.104:2376/v1.15/version: x509: certificate has expired or is not yet valid
  ```
  * ```
  Unable to query docker version: Get https://192.168.8.104:2376/v1.15/version: x509: certificate signed by unknown authority
  ```
This [issue thread] (https://github.com/sparkfabrik/sparkdock/issues/14) and [this docker issue thread](https://github.com/docker/machine/issues/4046) helped. They references [this docker doc]( https://docs.docker.com/machine/reference/regenerate-certs/)
      ```
      docker-machine regenerate-certs [your vm name]
      ```
After this, ``docker-machine ls`` showed the vms up and running and without errors.


### Initialize the swarm and add nodes

The first nodes will always be the manager
```
docker-machine ssh myvm1 "docker swarm init --advertise-addr <myvm1 ip>:<The daemon port, usually 2377>"
```
The response of this command gives instructions on how to add another node/worker or node/manager
```
docker-machine ssh myvm2 "<content of the response that correspond to the type of node to be added>"
```
To leave the swarm
```
docker-machine ssh <relevant machine> "docker swarm leave"
```


### Communicating with the nodes

We have used so far:
```
docker-machine ssh <relevant machine>
```
but alternatively
```
docker-machine env <relevant machine>
```
configures the current terminal to talk directly to the <relevant machine>.
The last line of the response to this command specifies what has to be done in order for the configuration to be finalized. In my case:
```
@FOR /f "tokens=*" %i IN ('docker-machine env myvm1') DO @%i
```

Then ``docker-machine ls`` will indicate in which machine the terminal is directly connected. Look at the asterisk in the ACTIVE column next to the <relevant machine>.


### Deploying the app/stack
From a terminal configured to talk directly to the node manager (If this is not the case, use a bash command line to transfer the docker-compose.yml file to the node manager with ``docker-machine scp <file> <machine>:~``)
```
docker stack deploy -c docker-compose.yml getstartedlab
```

``docker stack ps getstartedlab`` will give you the deployment status of your app/stack


### Accessing the cluster
The [docker doc](https://docs.docker.com/get-started/part4/) states that the following should allow you to hit the app endpoints:
```
http://<node ip address>  -  from the browser
curl http://<node ip address>  - from the terminal
```


However, it did not: ``curl http://192.168.8.104:2376 --output -`` and ``curl http://192.168.8.105:2376 --output -`` gave ``§♥☺ ☻☻`` 
where the ip address are the ip of my virtual machines. The port 2376 is the port of the daemon running on the machine.
Ping were going through: ``ping 192.168.8.104`` and ``ping 192.168.8.105``


After running, 
```
docker service inspect getstartedlab_web
```
where getstartedlab_web is the service created by ``docker-compose.yml``, it was noticed that the ``"PublishMode": "ingress"`` was implemented at ``"PublishedPort": 4000,`` under the ``Endpoint.Ports`` section of the terminal response.

then,
```
http://<node ip address>:<ingress port>  -  from the browser
curl http://<node ip address>:<ingress port>  - from the terminal
```
allowed me to hit the app's endpoints.


**Note**: For each execution of the above 2 commands, the host name is different (We are hitting different containers - horizontal scaling was successful). One can verify that the ***host names*** always belong to the ***container ids*** as given by:
```
docker-machine ssh myvm1 "docker container ls"
docker-machine ssh myvm2 "docker container ls"
```
